<p align="center">
    <img src="frontend/public/limas.png" alt="Lima's PDF Extractor logo" width="220" />
</p>

# Lima's PDF Extractor ‚Äî Enter AI Fellowship Take‚ÄëHome


> **Stack**: React + Vite (GitHub Pages) ‚Ä¢ FastAPI (Fly.io) ‚Ä¢ Supabase (Postgres, Storage, Realtime) ‚Ä¢ PyMuPDF ‚Ä¢ OpenAI `gpt-5-mini` (fallback opcional)

## ‚ú® Vis√£o geral

Uma solu√ß√£o ponta‚Äëa‚Äëponta para **extrair dados estruturados de PDFs (1 p√°gina, com OCR embutido)**, recebendo `(label, extraction_schema, pdf)` e retornando um **JSON** com os campos. O projeto prioriza **tempo < 10s**, **baixo custo** e **acur√°cia/consist√™ncia** com uma pipeline h√≠brida de **heur√≠sticas geom√©tricas + LLM como fallback inteligente**.

* **Frontend (GH Pages)**: UI em React que faz upload em lote, associa **schema‚Üîarquivo** por nome/ordem, cria o *job* no Supabase, acompanha o progresso em tempo real e permite **baixar o JSON combinado**.
* **Backend (Fly.io)**: FastAPI que processa cada PDF: baixa do bucket, roda a pipeline de extra√ß√£o e sobe o JSON de sa√≠da para o bucket de resultados.
* **Supabase**: armazena **jobs/job_items** (controle de orquestra√ß√£o), dois buckets (`docs` e `results`) e **realtime** para progresso.

---

## üß† Abordagem de extra√ß√£o (o ‚Äúcomo‚Äù)

A pipeline aplica **tr√™s est√°gios** com foco em custo/perf:

1. **√Çncoras + leitura local (heur√≠stico)** ‚Äî `anchors_reading_span.py`

   * O algoritmo gera varia√ß√µes do r√≥tulo do campo (normaliza√ß√£o, abrevia√ß√µes, *prefix cuts*, sem vogais) para encontrar **√¢ncoras** no layout do documento.
   * Utiliza "vetores" de texto para comparar √¢ncoras e campos, permitindo busca sem√¢ntica e maior flexibilidade na identifica√ß√£o, mesmo com pequenas diferen√ßas ou erros de digita√ß√£o.
   * A partir da √¢ncora localizada, extrai um **span de leitura** (direita/abaixo), respeitando limites de largura/altura, saltos de linha e toler√¢ncia vertical.
   * **Fast‚Äëpaths** sem LLM: utiliza regex para identificar padr√µes comuns como telefone, n√∫meros de inscri√ß√£o, CPF e datas.
* Resultado: valor bruto por campo, com limpeza (`sanitize_value_text`).

    <p align="center">
        <img src="frontend/public/rg_1_page1_span.png" alt="Exemplo de detec√ß√£o de √¢ncora e extra√ß√£o de span" width="600" />
    </p>

2. **LLM em lote por p√°gina**

   * Um √∫nico *prompt* passa **todos os campos da p√°gina** para **sanitizar e preencher apenas o que faltar** (responde `null` se ausente).
   * Limites r√≠gidos de texto (cortes de contexto) e `max_output_tokens` m√≠nimo.

3. **LLM ‚ÄúJSON extractor‚Äù final**

   * No texto completo (compactado) do doc, pede **somente** o JSON do schema **apenas para chaves faltantes** ou **componentes compostos**.
   * Sa√≠da √© *parsed* e aplicada campo‚Äëa‚Äëcampo, sem inventar valores (mant√©m `null`).

**Por que isso atende ao desafio**

* **<10s**: Heur√≠sticas s√£o O(1)/O(n) no n¬∫ de *tokens* de texto; LLM √© **fallback** limitado, com *caps* e *early exits*.
* **Custo baixo**: regex + layout evitam chamadas; quando LLM √© usado, √© **bulk** e recortado.
* **Acur√°cia ‚â• 80%**: mistura de **√¢ncora geom√©trica** + **sanitiza√ß√£o por LLM** lida com layouts que variam sem depender de *templates* fixos.

> C√≥digo principal da pipeline: `worker/anchors_reading_span.py` (usado tamb√©m no backend).

---

## üèóÔ∏è Arquitetura

```
[React UI (GH Pages)]
   ‚îî‚îÄ‚îÄ Upload PDFs + JSON (schema/dataset)
       ‚îî‚îÄ‚îÄ Supabase Storage (bucket: docs)
           ‚îî‚îÄ‚îÄ Cria job + job_items (Postgres) ‚îÄ‚îÄ‚ñ∫ Realtime
                       ‚îÇ
                       ‚ñº
                [FastAPI em Fly.io]
                  /healthz, /process-job
                       ‚îÇ
             baixa PDF do bucket (docs)
                       ‚îÇ
             processa (heur√≠stica + LLM)
                       ‚îÇ
             sobe JSON no bucket (results)
                       ‚îÇ
           atualiza job_items (status, tempo)
                       ‚îÇ
                       ‚ñº
           UI assina Realtime e mostra progresso
           + bot√£o ‚ÄúBaixar combinado‚Äù (merge dos JSONs)
```

---

## üóÉÔ∏è Modelo de dados (Supabase)

Tabelas (chaves m√≠nimas):

```sql
CREATE TABLE public.jobs (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  created_at timestamptz NOT NULL DEFAULT now(),
  created_by text,
  status text NOT NULL DEFAULT 'queued',
  total_count int NOT NULL DEFAULT 0,
  done_count int NOT NULL DEFAULT 0,
  error_count int NOT NULL DEFAULT 0,
  result_manifest jsonb,
  error_message text
);

CREATE TABLE public.job_items (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  job_id uuid REFERENCES public.jobs(id),
  created_at timestamptz NOT NULL DEFAULT now(),
  file_name text NOT NULL,
  file_path text NOT NULL,
  status text NOT NULL DEFAULT 'queued',
  duration_ms int,
  result_path text,
  error_message text,
  schema jsonb
);
```

Buckets de Storage:

* `docs` (entrada; PDFs) ‚Äî p√∫blico para leitura via servi√ßo; *upload* feito pelo frontend (anon key).
* `results` (sa√≠da; JSONs) ‚Äî pode ser p√∫blico para facilitar *download* direto pela UI (ou privado + URL assinada).

---

## üîå API do backend (FastAPI em Fly)

**Endpoints**

* `GET /healthz` ‚Üí `{ ok: true }` (usado pelo bot√£o ‚ÄúWake server‚Äù da UI).
* `POST /process-job { job_id }` ‚Üí dispara processamento do *job*.

**Seguran√ßa**

* Vers√£o simples: `app.py` (usa `run_job_id` s√≠ncrono; sem header secreto ‚Äî ideal para o take‚Äëhome/POC).
* Vers√£o protegida/concorrente: `main.py` (aceita `x-worker-secret`, *async* com `concurrency=3`, ajust√°vel para `1` se quiser 100% serial).

**Vari√°veis de ambiente (backend)**

* `SUPABASE_URL`, `SUPABASE_SERVICE_ROLE_KEY`
* `BUCKET_DOCS=docs`, `BUCKET_RESULTS=results`
* `WORKER_SECRET` (se usar `main.py`)
* `OPENAI_API_KEY`

Rodando local:

```bash
# Python 3.11+
python -m venv .venv && source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt

# Escolha 1: vers√£o simples
uvicorn app:app --reload --port 8000
# Escolha 2: vers√£o com secret/concurrency
export WORKER_SECRET=devsecret
uvicorn main:app --reload --port 8000
```

Deploy no Fly.io (resumo):

```bash
fly launch --no-deploy  # cria o app e o fly.toml
# Secrets
fly secrets set SUPABASE_URL=... SUPABASE_SERVICE_ROLE_KEY=... \
  BUCKET_DOCS=docs BUCKET_RESULTS=results OPENAI_API_KEY=... \
  WORKER_SECRET=...  # se usar main.py
fly deploy
```

> A UI aponta para `VITE_FLY_API_URL` (ex.: `https://take-home-enter.fly.dev`).

---

## üñ•Ô∏è Frontend (React + Vite + Tailwind)

**Principais recursos**

* **Upload em lote** (drag & drop).
* Campo JSON aceita:

  * **schema √∫nico** `{ "campo": null, ... }`, aplicado a todos os PDFs; ou
  * **dataset** `[{ label, extraction_schema, pdf_path? }]` e a UI faz *matching* **por nome** (`pdf_path`) ou **por ordem**.
* **Preview do mapeamento** com *badges* (`filename`, `ordem`, `schema √∫nico`) e alertas se houve *fallback* por ordem.
* **Progresso em tempo real** (Supabase Realtime), **m√©dia por PDF** ao terminar e **download do combinado**.
* **Wake server** + *status badge* (ok/conectando/erro).

**Vari√°veis de ambiente (frontend)**

* `VITE_SUPABASE_URL`
* `VITE_SUPABASE_ANON_KEY`
* `VITE_FLY_API_URL` (URL do backend)

Rodando local:

```bash
cd frontend
npm i
npm run dev  # http://localhost:5173
```

Deploy no GitHub Pages:

1. Habilite **Pages** (branch `gh-pages` ou via *workflow* `frontend/.github/workflows/pages.yaml`).
2. Configure `homepage`/`base` no Vite se o reposit√≥rio for *user/Take_home_enter* (o workflow j√° trata caminhos relativos).
3. Exporte `VITE_SUPABASE_URL`, `VITE_SUPABASE_ANON_KEY`, `VITE_FLY_API_URL` como **secrets** do reposit√≥rio (se necess√°rio para *build*).

---

## ‚öôÔ∏è Como usar (end‚Äëto‚Äëend)

### Como usar (end‚Äëto‚Äëend)

1. Acesse: [https://matheuslimam.github.io/Take_home_enter](https://matheuslimam.github.io/Take_home_enter)
2. Na interface, **cole um JSON** de schema (√∫nico ou dataset) e **arraste os PDFs** desejados.
3. Clique em **Processar**: a UI cria o `job` e os `job_items`, faz upload dos PDFs para o bucket `docs/` e aciona o backend via `/process-job`.
4. Acompanhe o **progresso em tempo real**; ao finalizar, utilize o bot√£o **Baixar combinado** para obter um arquivo `job-<id>-combined.json` com `{ file, result }` para cada PDF processado.

### Exemplos de schema (dataset)

```json
[
  {
    "label": "carteira_oab",
    "extraction_schema": {
      "nome": "Nome do profissional...",
      "inscricao": "N√∫mero de inscri√ß√£o...",
      "seccional": "UF...",
      "situacao": "Situa√ß√£o do profissional..."
    },
    "pdf_path": "oab_1.pdf"
  },
  {
    "label": "carteira_oab",
    "extraction_schema": {
      "nome": null,
      "inscricao": null,
      "seccional": null,
      "situacao": null
    },
    "pdf_path": "oab_2.pdf"
  }
]
```

---

## üî¨ Decis√µes e trade‚Äëoffs

* **LLM como ‚Äú√∫ltimo recurso‚Äù**: heur√≠sticas + regex resolvem a maior parte; LLM limpa/preenche apenas quando necess√°rio (e em **lote** para reduzir custo).
* **Contexto m√≠nimo**: cortes de texto (limites por p√°gina e total), *caps* de *tokens* de sa√≠da.
* **Variabilidade de layout**: busca por **√¢ncoras gen√©ricas** caso o r√≥tulo n√£o seja exatamente igual ao nome da chave, com pontua√ß√£o e repuls√£o de colis√£o de *bboxes*.
* **Serial vs. concorrente**: `run_job.py` processa **sequencialmente**; `main.py` permite **concurrency** (padr√£o 3) para melhorar *lat√™ncia m√©dia*. Pode ser `1` se a avalia√ß√£o exigir s√©rie estrita.
* **Custo**: uma chamada bulk + um *extractor* final somente quando h√° falta/ambiguidade ‚Äî otimizando *upper bound* do custo por documento.

---

## üìà M√©tricas vis√≠veis na UI

* **Status por item** (queued/running/done/error).
* **Tempo por item** (`duration_ms`).
* **M√©dia por PDF** ao final do job.

> A UI calcula a m√©dia apenas dos itens `done` com `duration_ms` definido e exibe com precis√£o de segundos.

---

## üîê Seguran√ßa e boas pr√°ticas

* **Service Role Key** s√≥ no **backend** (Fly). O frontend usa **anon key**.
* Habilite **RLS** nas tabelas e use **Policies** para restringir `insert/select/update` pelos usu√°rios do app (n√£o incluso por brevidade; recomend√°vel em produ√ß√£o).
* Se `results` for privado, gere **URLs assinadas** para baixar o JSON.
* Para `main.py`, configure header `x-worker-secret` no caller (UI/Edge) e **n√£o exponha** esse secret no cliente p√∫blico.

---

## üß™ Testes locais com o dataset p√∫blico

* Baixe o reposit√≥rio com PDFs de exemplo do desafio.
* Monte um **dataset JSON** (array) apontando `pdf_path` para cada arquivo do diret√≥rio local e teste com `anchors_reading_span.py` (modo CLI) ou pela UI.

Execu√ß√£o CLI

```bash
python worker/anchors_reading_span.py  # l√™ dataset3.json/Data/pdfs e imprime JSON final
```

---

## üìÇ Estrutura relevante do repo

```
.
‚îú‚îÄ frontend/                 # React + Vite + Tailwind (UI GH Pages)
‚îÇ  ‚îú‚îÄ src/App.tsx            # UI (upload, mapping, progresso, m√©dia, download)
‚îÇ  ‚îî‚îÄ src/lib/supabase.ts    # cliente supabase (anon)
‚îú‚îÄ worker/
‚îÇ  ‚îú‚îÄ anchors_reading_span.py# heur√≠sticas + LLM fallback + extractor JSON
‚îÇ  ‚îú‚îÄ run_job.py             # execu√ß√£o sequencial por job_item
‚îÇ  ‚îî‚îÄ main.py                # FastAPI async (secret + concurrency)
‚îú‚îÄ app.py                    # FastAPI simples (sem segredo, s√≠ncrono)
‚îú‚îÄ requirements.txt          # deps Python
‚îú‚îÄ fly.toml                  # config Fly
‚îî‚îÄ README.md                 # este arquivo
```

---

## üìù Checklist de entrega

* [x] Recebe `(label, schema, pdf)` e retorna JSON
* [x] Responde em <10s (m√©dia) com custos reduzidos (LLM m√≠nimo, heur√≠sticas primeiro)
* [x] UI funcional com progresso em tempo real + download de resultados
* [x] Execu√ß√£o em lote a partir de uma lista (dataset) ou schema √∫nico
* [x] Deploy: **Frontend em GitHub Pages** e **Backend em Fly.io**

---

## üõ†Ô∏è Troubleshooting


---

## üì£ Cr√©ditos

Desenvolvido por **Matheus Lima** ‚Äî *Lima's PDF Extractor*. Obrigado por avaliar! üôå
