<p align="center">
    <a href="https://matheuslimam.github.io/Take_home_enter" target="_blank">
        <img src="frontend/public/limas.png" alt="Acessar a ferramenta" width="220" style="margin-bottom: -45px;" />
        <br />
        <b style="color: #ffb301;">Clique aqui e Acesse a ferramenta</b>
    </a>
</p>

# Lima's PDF Extractor â€” Enter AI Fellowship Takeâ€‘Home

<p align="center">
    <b>Stack principal:</b><br>
    <img src="https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB" />
    <img src="https://img.shields.io/badge/Vite-646CFF?style=for-the-badge&logo=vite&logoColor=FFD62E" />
    <img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white" />
    <img src="https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&logo=supabase&logoColor=white" />
    <img src="https://img.shields.io/badge/PyMuPDF-3776AB?style=for-the-badge&logo=python&logoColor=white" />
    <img src="https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white" />
    <img src="https://img.shields.io/badge/GitHub%20Pages-222?style=for-the-badge&logo=github&logoColor=white" />
    <img src="https://img.shields.io/badge/Fly.io-000?style=for-the-badge" />
</p>



## âœ¨ VisÃ£o geral

Uma soluÃ§Ã£o pontaâ€‘aâ€‘ponta para **extrair dados estruturados de PDFs (1 pÃ¡gina, com OCR embutido)**, recebendo `(label, extraction_schema, pdf)` e retornando um **JSON** com os campos. O projeto prioriza **tempo < 10s**, **baixo custo** e **acurÃ¡cia/consistÃªncia** com uma pipeline hÃ­brida de **heurÃ­sticas geomÃ©tricas + LLM como fallback inteligente**.

* **Frontend (GH Pages)**: UI em React que faz upload em lote, associa **schemaâ†”arquivo** por nome/ordem, cria o *job* no Supabase, acompanha o progresso em tempo real e permite **baixar o JSON combinado**.
* **Backend (Fly.io)**: FastAPI que processa cada PDF: baixa do bucket, roda a pipeline de extraÃ§Ã£o e sobe o JSON de saÃ­da para o bucket de resultados.
* **Supabase**: armazena **jobs/job_items** (controle de orquestraÃ§Ã£o), dois buckets (`docs` e `results`) e **realtime** para progresso.

---

## ğŸ§  Abordagem de extraÃ§Ã£o (o â€œcomoâ€)

A pipeline aplica **trÃªs estÃ¡gios** com foco em custo/perf:

1. **Ã‚ncoras + leitura local (heurÃ­stico)** â€” `anchors_reading_span.py`

   * O algoritmo gera variaÃ§Ãµes do rÃ³tulo do campo (normalizaÃ§Ã£o, abreviaÃ§Ãµes, *prefix cuts*, sem vogais) para encontrar **Ã¢ncoras** no layout do documento.
   * Utiliza "vetores" de texto para comparar proximidade cosseno entre **Ã¢ncoras** e **campos** (Palavras prÃ³ximas, compostas ou simples), permitindo busca semÃ¢ntica e maior flexibilidade na identificaÃ§Ã£o, mesmo com pequenas diferenÃ§as ou erros de digitaÃ§Ã£o. Essa etapa ocorre em milesimos de segundos e tem uma acuracia mÃ©dia de 80% dos casos testados.
   * A partir da Ã¢ncora localizada, extrai um **span de leitura** (direita/abaixo), respeitando limites de largura/altura, saltos de linha e tolerÃ¢ncia vertical.
   * **Fastâ€‘paths** sem LLM: utiliza regex para identificar padrÃµes comuns como telefone, nÃºmeros de inscriÃ§Ã£o, CPF e datas. Mas evitando uso de dicionÃ¡rios especificos para deixar completament genÃ©rico.
* Resultado: valor bruto por campo, com limpeza (`sanitize_value_text`). Segue uma imagem de um exemplo que rodei somente nessa etapa:

    <p align="center">
        <img src="frontend/public/rg_1_page1_span.png" alt="Exemplo de detecÃ§Ã£o de Ã¢ncora e extraÃ§Ã£o de span" width="600" />
    </p>

2. **LLM em lote por pÃ¡gina**

   * Um Ãºnico *prompt* passa **todos os campos da pÃ¡gina** para **sanitizar e preencher apenas o que faltar** (responde `null` se ausente).
   * Limites rÃ­gidos de texto (cortes de contexto) e `max_output_tokens` mÃ­nimo.

3. **LLM â€œJSON extractorâ€ final**

   * No texto completo (compactado) do doc, pede **somente** o JSON do schema **apenas para chaves faltantes** ou **componentes compostos**.
   * SaÃ­da Ã© *parsed* e aplicada campoâ€‘aâ€‘campo, sem inventar valores (mantÃ©m `null`).

**Por que isso atende ao desafio**

* **<10s**: HeurÃ­sticas sÃ£o O(1)/O(n) no nÂº de *tokens* de texto; LLM Ã© **fallback** limitado, com *caps* e *early exits*.
* **Custo baixo**: regex + layout evitam chamadas; quando LLM Ã© usado, Ã© **bulk** e recortado.
* **AcurÃ¡cia â‰¥ 80%**: mistura de **Ã¢ncora geomÃ©trica** + **sanitizaÃ§Ã£o por LLM** lida com layouts que variam sem depender de *templates* fixos.

> CÃ³digo principal da pipeline: `worker/anchors_reading_span.py` (usado tambÃ©m no backend).

---

## ğŸ—ï¸ Arquitetura
<div align="center">

<!-- Mapa mental da arquitetura: Lima's PDF Extractor -->
<img src="frontend/public/tree.png" alt="Mapa mental da arquitetura" width="800" />

</div>

---

## ğŸ—ƒï¸ Modelo de dados (Supabase)

Tabelas (chaves mÃ­nimas):

```sql
CREATE TABLE public.jobs (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  created_at timestamptz NOT NULL DEFAULT now(),
  created_by text,
  status text NOT NULL DEFAULT 'queued',
  total_count int NOT NULL DEFAULT 0,
  done_count int NOT NULL DEFAULT 0,
  error_count int NOT NULL DEFAULT 0,
  result_manifest jsonb,
  error_message text
);

CREATE TABLE public.job_items (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  job_id uuid REFERENCES public.jobs(id),
  created_at timestamptz NOT NULL DEFAULT now(),
  file_name text NOT NULL,
  file_path text NOT NULL,
  status text NOT NULL DEFAULT 'queued',
  duration_ms int,
  result_path text,
  error_message text,
  schema jsonb
);
```

Buckets de Storage:

* `docs` (entrada; PDFs) â€” pÃºblico para leitura via serviÃ§o; *upload* feito pelo frontend (anon key).
* `results` (saÃ­da; JSONs) â€” pode ser pÃºblico para facilitar *download* direto pela UI (ou privado + URL assinada).

---

## ğŸ”Œ API do backend (FastAPI em Fly)

**Endpoints**

* `GET /healthz` â†’ `{ ok: true }` (usado pelo botÃ£o â€œWake serverâ€ da UI).
* `POST /process-job { job_id }` â†’ dispara processamento do *job*.

**SeguranÃ§a**

* VersÃ£o simples: `app.py` (usa `run_job_id` sÃ­ncrono; sem header secreto â€” ideal para o takeâ€‘home/POC).
* VersÃ£o protegida/concorrente: `main.py` (aceita `x-worker-secret`, *async* com `concurrency=3`, ajustÃ¡vel para `1` se quiser 100% serial).

**VariÃ¡veis de ambiente (backend)**

* `SUPABASE_URL`, `SUPABASE_SERVICE_ROLE_KEY`
* `BUCKET_DOCS=docs`, `BUCKET_RESULTS=results`
* `WORKER_SECRET` (se usar `main.py`)
* `OPENAI_API_KEY`

Rodando local:

```bash
# Python 3.11+
python -m venv .venv && source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt

# Escolha 1: versÃ£o simples
uvicorn app:app --reload --port 8000
# Escolha 2: versÃ£o com secret/concurrency
export WORKER_SECRET=devsecret
uvicorn main:app --reload --port 8000
```

Deploy no Fly.io (resumo):

```bash
fly launch --no-deploy  # cria o app e o fly.toml
# Secrets
fly secrets set SUPABASE_URL=... SUPABASE_SERVICE_ROLE_KEY=... \
  BUCKET_DOCS=docs BUCKET_RESULTS=results OPENAI_API_KEY=... \
  WORKER_SECRET=...  # se usar main.py
fly deploy
```

> A UI aponta para `VITE_FLY_API_URL` (ex.: `https://take-home-enter.fly.dev`).

---

## ğŸ–¥ï¸ Frontend (React + Vite + Tailwind)

<p align="center">
    <img src="frontend/public/tela.png" alt="Interface do frontend" width="700" />
    <br />
    <em>Exemplo da interface: upload em lote, mapeamento de schema, progresso e download.</em>
</p>

**Principais recursos**

> âš ï¸ **Aviso:** Existem **3 formas de aquecer o servidor** antes de processar os PDFs, pode demorar um pouco (mÃ©dia de 8s) para iniciar a queue:
> 1. Clicar no botÃ£o **Wake server** na interface (recomendada).
> 2. Quando colocamos um documento.
> 3. Realizar qualquer requisiÃ§Ã£o para o backend (ex.: iniciar um job).
> Isso garante que o backend esteja ativo e pronto para receber os arquivos.

* **Upload em lote** (drag & drop).
* Campo JSON aceita:

  * **schema Ãºnico** `{ "campo": null, ... }`, aplicado a todos os PDFs; ou
  * **dataset** `[{ label, extraction_schema, pdf_path? }]` e a UI faz *matching* **por nome** (`pdf_path`) ou **por ordem**.
* **Preview do mapeamento** com *badges* (`filename`, `ordem`, `schema Ãºnico`) e alertas se houve *fallback* por ordem.
* **Progresso em tempo real** (Supabase Realtime), **mÃ©dia por PDF** ao terminar e **download do combinado**.
* **Wake server** + *status badge* (ok/conectando/erro).

**VariÃ¡veis de ambiente (frontend)**

* `VITE_SUPABASE_URL`
* `VITE_SUPABASE_ANON_KEY`
* `VITE_FLY_API_URL` (URL do backend)

Rodando local:

```bash
cd frontend
npm i
npm run dev  # http://localhost:5173
```

Deploy no GitHub Pages:

1. Habilite **Pages** (branch `gh-pages` ou via *workflow* `frontend/.github/workflows/pages.yaml`).
2. Configure `homepage`/`base` no Vite se o repositÃ³rio for *user/Take_home_enter* (o workflow jÃ¡ trata caminhos relativos).
3. Exporte `VITE_SUPABASE_URL`, `VITE_SUPABASE_ANON_KEY`, `VITE_FLY_API_URL` como **secrets** do repositÃ³rio (se necessÃ¡rio para *build*).

---

## âš™ï¸ Como usar (endâ€‘toâ€‘end)

### Usando a UI

1. Acesse: [https://matheuslimam.github.io/Take_home_enter](https://matheuslimam.github.io/Take_home_enter)
2. Na interface, **cole um JSON** de schema (Ãºnico ou dataset) e **arraste os PDFs** desejados.
3. Clique em **Processar**: a UI cria o `job` e os `job_items`, faz upload dos PDFs para o bucket `docs/` e aciona o backend via `/process-job`.
4. Acompanhe o **progresso em tempo real**; ao finalizar, utilize o botÃ£o **Baixar combinado** para obter um arquivo `job-<id>-combined.json` com `{ file, result }` para cada PDF processado.


### Exemplos de schema (dataset)

```json
[
  {
    "label": "carteira_oab",
    "extraction_schema": {
      "nome": "Nome do profissional...",
      "inscricao": "NÃºmero de inscriÃ§Ã£o...",
      "seccional": "UF...",
      "situacao": "SituaÃ§Ã£o do profissional..."
    },
    "pdf_path": "oab_1.pdf"
  },
  {
    "label": "carteira_oab",
    "extraction_schema": {
      "nome": null,
      "inscricao": null,
      "seccional": null,
      "situacao": null
    },
    "pdf_path": "oab_2.pdf"
  }
]
```

---

## ğŸ”¬ DecisÃµes e tradeâ€‘offs

* **LLM como â€œÃºltimo recursoâ€**: heurÃ­sticas + regex resolvem a maior parte; LLM limpa/preenche apenas quando necessÃ¡rio (e em **lote** para reduzir custo).
* **Contexto mÃ­nimo**: cortes de texto (limites por pÃ¡gina e total), *caps* de *tokens* de saÃ­da.
* **Variabilidade de layout**: busca por **Ã¢ncoras genÃ©ricas** caso o rÃ³tulo nÃ£o seja exatamente igual ao nome da chave, com pontuaÃ§Ã£o e repulsÃ£o de colisÃ£o de *bboxes*.
* **Serial vs. concorrente**: `run_job.py` processa **sequencialmente**; `main.py` permite **concurrency** (padrÃ£o 3) para melhorar *latÃªncia mÃ©dia*. Pode ser `1` se a avaliaÃ§Ã£o exigir sÃ©rie estrita.
* **Custo**: uma chamada bulk + um *extractor* final somente quando hÃ¡ falta/ambiguidade â€” otimizando *upper bound* do custo por documento.

---

## ğŸ“ˆ MÃ©tricas visÃ­veis na UI

* **Status por item** (queued/running/done/error).
* **Tempo por item** (`duration_ms`).
* **MÃ©dia por PDF** ao final do job.

> A UI calcula a mÃ©dia apenas dos itens `done` com `duration_ms` definido e exibe com precisÃ£o de segundos.

---

## ğŸ” SeguranÃ§a e boas prÃ¡ticas

* **Service Role Key** sÃ³ no **backend** (Fly). O frontend usa **anon key**.
* Habilite **RLS** nas tabelas e use **Policies** para restringir `insert/select/update` pelos usuÃ¡rios do app (nÃ£o incluso por brevidade; recomendÃ¡vel em produÃ§Ã£o).
* Se `results` for privado, gere **URLs assinadas** para baixar o JSON.
* Para `main.py`, configure header `x-worker-secret` no caller (UI/Edge) e **nÃ£o exponha** esse secret no cliente pÃºblico.

---

## ğŸ§ª Testes locais com o dataset pÃºblico

Se a UI, nÃ£o funcionar de alguma forma, apresentar lentidÃ£o ou estÃ¡ sem internet.
* Baixe o repositÃ³rio com PDFs de exemplo do desafio.
* Monte um **dataset JSON** (array) apontando `pdf_path` para cada arquivo do diretÃ³rio local e teste com `anchors_reading_span.py` (modo CLI) ou pela UI.

ExecuÃ§Ã£o CLI

```bash
python worker/anchors_reading_span.py  # lÃª dataset3.json/Data/pdfs e imprime JSON final
```

---

## ğŸ“‚ Estrutura relevante do repo

```
.
â”œâ”€ frontend/                   # React + Vite + Tailwind (UI GH Pages)
â”‚  â”œâ”€ src/App.tsx              # UI (upload, mapping, progresso, mÃ©dia, download)
â”‚  â””â”€ src/lib/supabase.ts      # cliente supabase (anon)
â”œâ”€ worker/
â”‚  â”œâ”€ anchors_reading_span.py  # heurÃ­sticas + LLM fallback + extractor JSON
â”‚  â”œâ”€ run_job.py               # execuÃ§Ã£o sequencial por job_item
â”‚  â””â”€ main.py                  # FastAPI async (secret + concurrency)
â”œâ”€ app.py                      # FastAPI simples (sem segredo, sÃ­ncrono)
â”œâ”€ requirements.txt            # deps Python
â”œâ”€ fly.toml                    # config Fly
â””â”€ README.md                   # este arquivo
```

---

## ğŸ“ Checklist de entrega

* [x] Recebe `(label, schema, pdf)` e retorna JSON
* [x] Responde em <10s (mÃ©dia) com custos reduzidos (LLM mÃ­nimo, heurÃ­sticas primeiro)
* [x] UI funcional com progresso em tempo real + download de resultados
* [x] ExecuÃ§Ã£o em lote a partir de uma lista (dataset) ou schema Ãºnico
* [x] Deploy: **Frontend em GitHub Pages** e **Backend em Fly.io**

---

## ğŸ› ï¸ Troubleshooting




---

## ğŸ“£ CrÃ©ditos

Desenvolvido por **Matheus Lima** â€” *Lima's PDF Extractor*. Obrigado por avaliar! ğŸ™Œ
